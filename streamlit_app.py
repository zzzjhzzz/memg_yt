# streamlit_app.py â€” ë‹¨ê³„ë³„ ë¡œê·¸/ì§„í–‰ë¥ /ì¬ì‹œë„ ë¡œê·¸ ì¶”ê°€ ë²„ì „
# ì£¼ìš” ë³€ê²½ì 
# - Logger í´ë˜ìŠ¤ë¡œ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ (ì¢Œì¸¡ "ì‹¤ì‹œê°„ ë¡œê·¸" íŒ¨ë„)
# - st.status()ë¡œ ë‹¨ê³„ë³„ ìƒíƒœ í‘œì‹œ (YTA â†’ yt-dlp â†’ pytube)
# - ì§„í–‰ë¥  ë°”: ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜
# - yt-dlp ìë§‰ URL GET ì‹œì—ë„ UA/ì¿ í‚¤/ì–¸ì–´ í—¤ë” ì ìš© + ì¬ì‹œë„ ë¡œê·¸
# - ê° ë‹¨ê³„ë³„ í›„ë³´ ì–¸ì–´/í¬ë§·/ì¬ì‹œë„ ìƒì„¸ ë¡œê·¸

import re
import random
import time
from time import sleep
import html
from typing import Optional, List
from urllib.parse import urlparse, parse_qs
import ssl
import json
import urllib.request

import streamlit as st
from youtube_transcript_api import (
    YouTubeTranscriptApi,
    NoTranscriptFound,
    TranscriptsDisabled,
    VideoUnavailable,
)
from pytube import YouTube
import yt_dlp

# ===== ê³µí†µ =====
class TranscriptExtractionError(Exception):
    pass

ssl._create_default_https_context = ssl._create_unverified_context

def build_common_headers(ua: str = None) -> dict:
    return {
        "User-Agent": ua or random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36",
        ]),
        "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8",
        "Cookie": "CONSENT=YES+cb",
        "Accept": "*/*",
        "Connection": "close",
    }

def urlopen_with_headers(url: str, headers: dict, logger, timeout: int = 30, retries: int = 3):
    last_err = None
    for attempt in range(retries):
        try:
            opener = urllib.request.build_opener()
            opener.addheaders = list(headers.items())
            logger.add(f"[GET] ìë§‰ íŒŒì¼ ìš”ì²­: {url.split('?')[0]}... (ì‹œë„ {attempt+1}/{retries})")
            with opener.open(url, timeout=timeout) as resp:
                data = resp.read()
                logger.add(f"[GET] ì„±ê³µ ({len(data)} bytes)")
                return data
        except Exception as e:
            last_err = e
            msg = str(e).lower()
            logger.add(f"[GET] ì‹¤íŒ¨: {e}")
            if any(x in msg for x in ["429", "too many requests", "temporarily", "timed out", "403", "unavailable"]):
                wait = (2 ** attempt) + random.uniform(0.5, 1.5)
                logger.add(f"[GET] ë°±ì˜¤í”„ {wait:.1f}s í›„ ì¬ì‹œë„")
                sleep(wait)
                continue
            break
    raise last_err

# ===== Logger =====
class Logger:
    def __init__(self, container):
        self.lines = []
        self.container = container

    def add(self, msg):
        now = time.strftime("%H:%M:%S")
        self.lines.append(f"[{now}] {msg}")
        self.container.write("\n".join(self.lines[-200:]))

# ===== URL/ID ìœ í‹¸ =====
YOUTUBE_URL_RE = re.compile(
    r'(?:https?://)?(?:www\.)?(?:youtube\.com/(?:watch\?v=|embed/|live/|shorts/)|youtu\.be/)([\w-]{11})(?:\S+)?'
)

def extract_video_id(url: str) -> Optional[str]:
    if not url:
        return None
    m = YOUTUBE_URL_RE.search(url)
    if m:
        return m.group(1)
    try:
        parsed = urlparse(url)
        if parsed.hostname in ["youtube.com", "www.youtube.com"]:
            vid = parse_qs(parsed.query).get("v", [None])[0]
            if vid and len(vid) == 11:
                return vid
        elif parsed.hostname in ["youtu.be", "www.youtu.be"]:
            vid = parsed.path.lstrip("/")
            if len(vid) == 11:
                return vid
    except Exception:
        pass
    return None

def to_clean_watch_url(url_or_id: str) -> str:
    vid = extract_video_id(url_or_id) if "http" in url_or_id else url_or_id
    return f"https://www.youtube.com/watch?v={vid}" if vid else url_or_id

# ===== ë©”íƒ€ (ì„ íƒ) =====
def safe_get_youtube_info(url: str, logger: Logger = None):
    try:
        ydl_opts = {"quiet": True, "noplaylist": True, "extract_flat": False}
        if logger: logger.add("yt-dlpë¡œ ì˜ìƒ ë©”íƒ€ ìš”ì²­")
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
        class YouTubeInfo:
            def __init__(self, d):
                self.title = d.get("title", "ì œëª© í™•ì¸ ë¶ˆê°€")
                self.length = d.get("duration", 0)
        if logger: logger.add("ë©”íƒ€ ìˆ˜ì‹  ì™„ë£Œ")
        return YouTubeInfo(info)
    except Exception as e:
        if logger: logger.add(f"ë©”íƒ€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        st.caption(f"ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)[:60]}")
        return None

# ===== 1) YTA =====
def fetch_via_yta_with_retry(video_id: str, langs: List[str], logger: Logger, max_retries: int = 3) -> str:
    last_error = None
    logger.add(f"[YTA] ì‹œì‘ â€” video_id={video_id}, ì„ í˜¸ì–¸ì–´={langs}")
    for attempt in range(max_retries):
        try:
            logger.add(f"[YTA] transcripts ëª©ë¡ ì¡°íšŒ (ì‹œë„ {attempt+1}/{max_retries})")
            tl = YouTubeTranscriptApi.list_transcripts(video_id)
            try:
                logger.add("[YTA] ì—…ë¡œë” ì œê³µ ìë§‰ ìš°ì„  íƒìƒ‰")
                tr = tl.find_transcript(langs)
            except Exception:
                logger.add("[YTA] ì—…ë¡œë” ìë§‰ ì—†ìŒ â†’ ìë™ ìƒì„± ìë§‰ íƒìƒ‰")
                tr = tl.find_generated_transcript(langs)
            logger.add(f"[YTA] ë§¤ì¹­: language={tr.language}, is_generated={tr.is_generated}")
            entries = tr.fetch()
            logger.add(f"[YTA] fetch ì„±ê³µ, ë¼ì¸ {len(entries)}")
            st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (YTA): {tr.language}" + (" [ìë™]" if tr.is_generated else " [ìˆ˜ë™]"))
            return "\n".join([f"[{e['start']:.1f}] {e['text']}" for e in entries])
        except Exception as e:
            last_error = e
            msg = str(e).lower()
            logger.add(f"[YTA] ì‹¤íŒ¨: {e}")
            if ("429" in msg or "too many requests" in msg) and attempt < max_retries - 1:
                wait = (2 ** attempt) + random.uniform(1, 3)
                logger.add(f"[YTA] 429/ì¼ì‹œì˜¤ë¥˜ â†’ {wait:.1f}s ëŒ€ê¸° í›„ ì¬ì‹œë„")
                sleep(wait)
                continue
            if isinstance(e, (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable)):
                raise
            raise TranscriptExtractionError(f"YTA ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    raise TranscriptExtractionError(f"YTA ì¬ì‹œë„ ì‹¤íŒ¨: {str(last_error)}")

# ===== 2) pytube =====
def clean_xml_text(xml_text: str) -> List[tuple]:
    items = []
    xml_text = xml_text.replace("\n", "")
    pattern = r'<text[^>]*start="([\d\.]+)"[^>]*>(.*?)</text>'
    for m in re.finditer(pattern, xml_text, re.DOTALL):
        try:
            start = float(m.group(1))
            raw = re.sub(r"<.*?>", " ", m.group(2))
            text = html.unescape(raw)
            text = re.sub(r"\s+", " ", text).strip()
            if text:
                items.append((start, text))
        except ValueError:
            continue
    return items

def fetch_via_pytube(url_or_id: str, langs: List[str], logger: Logger) -> str:
    url = to_clean_watch_url(url_or_id)
    try:
        logger.add(f"[pytube] ì‹œì‘ â€” {url}")
        yt = YouTube(url, use_oauth=False, allow_oauth_cache=False)
        _ = yt.title
        tracks = yt.captions
        if not tracks:
            raise TranscriptExtractionError("pytube: ìë§‰ íŠ¸ë™ì´ ì—†ìŒ")
        candidates = []
        for lg in langs:
            candidates += [lg, f"a.{lg}"]
        if "en" not in [c.replace("a.", "") for c in candidates]:
            candidates += ["en", "a.en"]
        available = {c.code: c for c in tracks}
        logger.add(f"[pytube] ì œê³µ ì½”ë“œ: {list(available.keys())}")
        for code in list(candidates):
            cap = available.get(code)
            if not cap:
                for k, v in available.items():
                    if k.lower().startswith(code.lower().replace("a.", "")):
                        cap = v; code = k; break
            if not cap:
                continue
            logger.add(f"[pytube] ì‹œë„: {code} (SRTâ†’XML)")
            try:
                srt = cap.generate_srt_captions()
                lines = []
                for block in srt.strip().split("\n\n"):
                    parts = block.split("\n")
                    if len(parts) >= 3:
                        ts = parts[1].split("-->")[0].strip()
                        try:
                            h, m, s_ms = ts.split(":")
                            s, ms = s_ms.split(",")
                            start = int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0
                            text = " ".join(parts[2:]).strip()
                            if text:
                                lines.append(f"[{start:.1f}] {text}")
                        except Exception:
                            continue
                if lines:
                    st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (pytube): {code}")
                    return "\n".join(lines)
            except Exception:
                try:
                    xml = cap.xml_captions
                    items = clean_xml_text(xml)
                    if items:
                        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (pytube): {code}")
                        return "\n".join([f"[{stt:.1f}] {txt}" for stt, txt in items])
                except Exception:
                    continue
    except Exception as e:
        raise TranscriptExtractionError(f"pytube ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    raise TranscriptExtractionError(
        f"pytube: ë§¤ì¹­ë˜ëŠ” ìë§‰ ì—†ìŒ (ì‚¬ìš©ê°€ëŠ¥: {list(available.keys()) if 'available' in locals() else 'N/A'})"
    )

# ===== 3) yt-dlp =====
def parse_vtt(vtt: str) -> List[str]:
    lines = []
    blocks = [b for b in vtt.strip().split("\n\n") if "-->" in b]
    for block in blocks:
        rows = block.split("\n")
        if not rows: continue
        ts = rows[0].replace(",", ".")
        m = re.match(r"(\d+):(\d+):(\d+(?:\.\d+)?)", ts)
        start = 0.0
        if m:
            h, m_, s = m.groups()
            start = int(h) * 3600 + int(m_) * 60 + float(s)
        text = " ".join(rows[1:]).strip()
        text = re.sub(r"<.*?>", " ", text)
        text = re.sub(r"\s+", " ", text)
        if text: lines.append(f"[{start:.1f}] {text}")
    return lines

def parse_srv3_json(json_data: str) -> List[str]:
    try:
        data = json.loads(json_data)
        lines = []
        for event in data.get("events", []):
            start_time = event.get("tStartMs", 0) / 1000.0
            segs = event.get("segs", [])
            text = "".join([seg.get("utf8", "") for seg in segs]).strip()
            if text: lines.append(f"[{start_time:.1f}] {text}")
        return lines
    except Exception:
        return []

def parse_ttml(ttml_data: str) -> List[str]:
    try:
        lines = []
        pattern = r'<p[^>]*begin="([^"]*)"[^>]*>(.*?)</p>'
        for match in re.finditer(pattern, ttml_data, re.DOTALL):
            time_str = match.group(1)
            text_content = match.group(2)
            try:
                parts = time_str.replace(",", ".").split(":")
                if len(parts) == 3:
                    h, m, s = parts
                    start_time = int(h) * 3600 + int(m) * 60 + float(s)
                else:
                    start_time = 0.0
            except:
                start_time = 0.0
            text = re.sub(r"<.*?>", " ", text_content)
            text = html.unescape(text)
            text = re.sub(r"\s+", " ", text).strip()
            if text: lines.append(f"[{start_time:.1f}] {text}")
        return lines
    except Exception:
        return []

def fetch_via_ytdlp_enhanced(url_or_id: str, langs: List[str], logger: Logger) -> str:
    url = to_clean_watch_url(url_or_id)
    common_headers = build_common_headers()
    ydl_opts = {
        "quiet": True,
        "no_warnings": True,
        "noplaylist": True,
        "writesubtitles": False,
        "writeautomaticsub": False,
        "socket_timeout": 60,
        "retries": 3,
        "http_headers": common_headers,
    }
    logger.add(f"[yt-dlp] ì‹œì‘ â€” {url} / ì„ í˜¸ì–¸ì–´={langs}")
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
        logger.add("[yt-dlp] info ì¶”ì¶œ ì„±ê³µ")
    except Exception as e:
        logger.add(f"[yt-dlp] info ì‹¤íŒ¨: {e}")
        raise TranscriptExtractionError(f"yt-dlp ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    subs = info.get("subtitles") or {}
    autos = info.get("automatic_captions") or {}
    logger.add(f"[yt-dlp] ì œê³µ ìˆ˜ë™ìë§‰: {list(subs.keys())} / ìë™ìë§‰: {list(autos.keys())}")

    candidates = []
    for lg in langs:
        if lg in subs: candidates.append(("manual", lg, subs[lg]))
    for lg in langs:
        if lg in autos: candidates.append(("auto", lg, autos[lg]))
    if "en" not in langs:
        if "en" in subs: candidates.append(("manual", "en", subs["en"]))
        if "en" in autos: candidates.append(("auto", "en", autos["en"]))
    if not candidates:
        all_available = list(subs.keys()) + list(autos.keys())
        if all_available:
            first_lang = all_available[0]
            if first_lang in subs:
                candidates.append(("manual", first_lang, subs[first_lang]))
            elif first_lang in autos:
                candidates.append(("auto", first_lang, autos[first_lang]))
    logger.add(f"[yt-dlp] í›„ë³´ íŠ¸ë™: {[(k, lg, len(lst)) for k, lg, lst in candidates]}")

    format_priority = ["vtt", "webvtt", "srv3", "ttml", "json3"]
    for kind, lg, fmt_list in candidates:
        if not fmt_list: continue
        sorted_formats = []
        for fmt_name in format_priority:
            for item in fmt_list:
                if item.get("ext", "").lower() == fmt_name:
                    sorted_formats.append(item)
        for item in fmt_list:
            if item not in sorted_formats:
                sorted_formats.append(item)

        for item in sorted_formats:
            ext = item.get("ext", "").lower()
            logger.add(f"[yt-dlp] ë‹¤ìš´ë¡œë“œ ì‹œë„: lang={lg}, kind={kind}, ext={ext}")
            try:
                data_bytes = urlopen_with_headers(item["url"], common_headers, logger, timeout=30, retries=3)
                data = data_bytes.decode("utf-8", errors="ignore")
                if ext in ("vtt", "webvtt"):
                    lines = parse_vtt(data)
                    logger.add(f"[yt-dlp] VTT íŒŒì‹± ë¼ì¸: {len(lines)}")
                    if lines:
                        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (yt-dlp): {lg} ({kind}, {ext.upper()})")
                        return "\n".join(lines)
                elif ext in ("srv3", "json3"):
                    lines = parse_srv3_json(data)
                    logger.add(f"[yt-dlp] SRV3 íŒŒì‹± ë¼ì¸: {len(lines)}")
                    if lines:
                        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (yt-dlp): {lg} ({kind}, SRV3)")
                        return "\n".join(lines)
                elif ext == "ttml":
                    lines = parse_ttml(data)
                    logger.add(f"[yt-dlp] TTML íŒŒì‹± ë¼ì¸: {len(lines)}")
                    if lines:
                        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (yt-dlp): {lg} ({kind}, TTML)")
                        return "\n".join(lines)
                else:
                    text = re.sub(r"<.*?>", " ", data)
                    text = html.unescape(text)
                    text = re.sub(r"\s+", " ", text).strip()
                    logger.add(f"[yt-dlp] ê¸°íƒ€ í¬ë§· ê¸¸ì´: {len(text)}")
                    if text and len(text) > 100:
                        st.success(f"âœ… ìë§‰ ì¶”ì¶œ ì„±ê³µ (yt-dlp): {lg} ({kind}, {ext.upper()})")
                        return text
            except Exception as e:
                logger.add(f"[yt-dlp] í¬ë§· ì‹œë„ ì‹¤íŒ¨: {e}")
                continue

    available_langs = list(set(list(subs.keys()) + list(autos.keys())))
    raise TranscriptExtractionError(f"yt-dlp: ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨ (ì‚¬ìš©ê°€ëŠ¥: {available_langs})")

# ===== ìµœì¢… ë˜í¼ + ìºì‹œ + ì§„í–‰ë¥  =====
def fetch_transcript_resilient(url: str, video_id: str, langs: List[str], logger: Logger, progress):
    # ìºì‹œ
    if "transcript_cache" not in st.session_state:
        st.session_state.transcript_cache = {}
    cache_key = (video_id, tuple(langs))
    if cache_key in st.session_state.transcript_cache:
        logger.add("ìºì‹œ íˆíŠ¸: ì´ì „ ì¶”ì¶œ ê²°ê³¼ ì‚¬ìš©")
        return st.session_state.transcript_cache[cache_key]

    # ì§„í–‰ë¥  ê°€ì¤‘ì¹˜: YTA 40% â†’ yt-dlp 40% â†’ pytube 20%
    def set_progress(p): progress.progress(min(max(int(p), 0), 100))

    errors = []
    with st.status("YTA ì‹œë„ ì¤‘...", state="running") as s1:
        set_progress(10)
        try:
            text = fetch_via_yta_with_retry(video_id, langs, logger)
            st.session_state.transcript_cache[cache_key] = text
            set_progress(100)
            s1.update(label="YTA ì„±ê³µ", state="complete")
            return text
        except (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable) as e:
            errors.append(f"YTA: {str(e)}"); s1.update(label="YTA: ìë§‰ ì—†ìŒ/ë¹„í™œì„±/ì ‘ê·¼ë¶ˆê°€", state="error")
        except TranscriptExtractionError as e:
            errors.append(f"YTA: {str(e)}"); s1.update(label="YTA: ì²˜ë¦¬ ì‹¤íŒ¨", state="error")
        except Exception as e:
            errors.append(f"YTA: {str(e)}"); s1.update(label="YTA: ì˜ˆì™¸", state="error")
        set_progress(40)

    with st.status("yt-dlp ì‹œë„ ì¤‘...", state="running") as s2:
        try:
            text = fetch_via_ytdlp_enhanced(url, langs, logger)
            st.session_state.transcript_cache[cache_key] = text
            set_progress(100)
            s2.update(label="yt-dlp ì„±ê³µ", state="complete")
            return text
        except TranscriptExtractionError as e:
            errors.append(f"yt-dlp: {str(e)}"); s2.update(label="yt-dlp: ì²˜ë¦¬ ì‹¤íŒ¨", state="error")
        except Exception as e:
            errors.append(f"yt-dlp: {str(e)}"); s2.update(label="yt-dlp: ì˜ˆì™¸", state="error")
        set_progress(80)

    with st.status("pytube ì‹œë„ ì¤‘...", state="running") as s3:
        try:
            text = fetch_via_pytube(url, langs, logger)
            st.session_state.transcript_cache[cache_key] = text
            set_progress(100)
            s3.update(label="pytube ì„±ê³µ", state="complete")
            return text
        except TranscriptExtractionError as e:
            errors.append(f"pytube: {str(e)}"); s3.update(label="pytube: ì²˜ë¦¬ ì‹¤íŒ¨", state="error")
        except Exception as e:
            errors.append(f"pytube: {str(e)}"); s3.update(label="pytube: ì˜ˆì™¸", state="error")
        set_progress(100)

    with st.expander("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´", expanded=False):
        for i, err in enumerate(errors, 1):
            st.text(f"{i}. {err}")

    if any("429" in err or "too many requests" in err.lower() for err in errors):
        raise TranscriptExtractionError("YouTube ìš”ì²­ ì œí•œ (429/ì¼ì‹œ ì°¨ë‹¨)")
    if any("ìë§‰" in err and ("ì—†ìŒ" in err or "ì°¾ì„ ìˆ˜ ì—†ìŒ" in err) for err in errors):
        raise TranscriptExtractionError("ì´ ì˜ìƒì—ëŠ” ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.")
    raise TranscriptExtractionError("ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨ - ìƒì„¸ ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# ===== Streamlit UI =====
st.set_page_config(page_title="YouTube ìë§‰ ì¶”ì¶œê¸° (ë¡œê·¸ ë²„ì „)", layout="wide")
st.title("ğŸ¬ YouTube ìë§‰ ì¶”ì¶œê¸°")
st.caption("ë‹¨ê³„ë³„ ë¡œê·¸ì™€ ì§„í–‰ë¥ ì„ í‘œì‹œí•©ë‹ˆë‹¤. (ì›¹ ì—”ë“œí¬ì¸íŠ¸ ê¸°ë°˜)")

with st.sidebar:
    st.header("ì„¤ì •")
    lang_pref = st.multiselect(
        "ì–¸ì–´ ìš°ì„ ìˆœìœ„",
        ["ko", "en", "ja", "zh-Hans", "zh-Hant", "es", "fr", "de"],
        default=["ko", "en"],
    )
    show_meta = st.toggle("ì˜ìƒ ì œëª©/ê¸¸ì´ í‘œì‹œ (ì¶”ê°€ ìš”ì²­ ë°œìƒ)", value=False)
    st.markdown("---")
    st.caption("429/ê°„í— ì‹¤íŒ¨ê°€ ì¦ë‹¤ë©´ í˜¸ì¶œ ë¹ˆë„ë¥¼ ë‚®ì¶”ê³ , ê°™ì€ ì˜ìƒì€ ìºì‹œê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.")

left, right = st.columns([1.1, 2.9])

with left:
    url = st.text_input("YouTube ë§í¬", placeholder="https://www.youtube.com/watch?v=... ë˜ëŠ” https://youtu.be/...")
    run = st.button("ìë§‰ ì¶”ì¶œ", type="primary")
    st.markdown("### ğŸ›°ï¸ ì‹¤ì‹œê°„ ë¡œê·¸")
    log_area = st.empty()

with right:
    progress = st.progress(0)

if run:
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”."); st.stop()
    clean_url = to_clean_watch_url(url.strip())
    vid = extract_video_id(clean_url)
    if not vid:
        st.error("ìœ íš¨í•œ YouTube ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤."); st.stop()

    logger = Logger(log_area)
    logger.add(f"ì…ë ¥ URL ì •ê·œí™”: {clean_url} (video_id={vid})")

    if show_meta:
        with st.spinner("ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            info = safe_get_youtube_info(clean_url, logger)
            if info:
                length_min = int((info.length or 0) / 60) if info.length else 0
                st.info(f"**ì œëª©**: {info.title}  |  **ê¸¸ì´**: ì•½ {length_min}ë¶„")
            else:
                st.caption("ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - ìë§‰ ì¶”ì¶œ ê³„ì†")

    with st.spinner("ìë§‰ ì¶”ì¶œ ì¤‘..."):
        try:
            text = fetch_transcript_resilient(clean_url, vid, lang_pref, logger, progress)
        except TranscriptExtractionError as e:
            st.error(f"âŒ {str(e)}"); st.stop()
        except (NoTranscriptFound, TranscriptsDisabled) as e:
            st.error(f"âŒ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"); st.stop()
        except VideoUnavailable:
            st.error("âŒ ì˜ìƒì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ë¹„ê³µê°œ/ì§€ì—­/ì—°ë ¹ ì œí•œ ë“±)"); st.stop()
        except Exception as e:
            st.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"); st.stop()

    st.success("ìë§‰ ì¶”ì¶œ ì™„ë£Œ!")
    c1, c2 = st.columns([1, 4])
    with c1:
        st.download_button(
            "ğŸ“„ ìë§‰ ë‹¤ìš´ë¡œë“œ (TXT)",
            data=text.encode("utf-8"),
            file_name=f"transcript_{vid}.txt",
            mime="text/plain",
        )
    with c2:
        st.caption(f"ì´ {len(text.split()):,}ê°œ ë‹¨ì–´")

    st.subheader("ğŸ“„ ì¶”ì¶œëœ ìë§‰")
    st.text_area("", value=text, height=500)

st.markdown("---")
st.caption("ğŸ’¡ ê³µìœ  IP/ë¬´ë£Œ í˜¸ìŠ¤íŒ… í™˜ê²½ì—ì„  429ê°€ ë” ìì£¼ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë™ì¼ ì˜ìƒ ì¬ìš”ì²­ì€ ìºì‹œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
