import re
import time
import html
from typing import Optional, List
from urllib.parse import urlparse, parse_qs
from urllib.request import urlopen
import ssl

import streamlit as st
from youtube_transcript_api import (
    YouTubeTranscriptApi,
    NoTranscriptFound,
    TranscriptsDisabled,
    VideoUnavailable,
)

# ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜
class TranscriptExtractionError(Exception):
    """ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì˜ˆì™¸"""
    pass
from pytube import YouTube
import yt_dlp

# SSL ì¸ì¦ì„œ ë¬¸ì œ í•´ê²°
ssl._create_default_https_context = ssl._create_unverified_context

# ---------------------------------
# URL ì •ë¦¬ / ë¹„ë””ì˜¤ID ì¶”ì¶œ
# ---------------------------------
YOUTUBE_URL_RE = re.compile(
    r'(?:https?://)?(?:www\.)?(?:youtube\.com/(?:watch\?v=|embed/|live/|shorts/)|youtu\.be/)([\w-]{11})(?:\S+)?'
)

def extract_video_id(url: str) -> Optional[str]:
    if not url:
        return None
    
    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë¨¼ì € ì‹œë„
    m = YOUTUBE_URL_RE.search(url)
    if m:
        return m.group(1)
    
    # URL íŒŒì‹±ìœ¼ë¡œ ì¬ì‹œë„
    try:
        parsed = urlparse(url)
        if parsed.hostname in ['youtube.com', 'www.youtube.com']:
            vid = parse_qs(parsed.query).get("v", [None])[0]
            if vid and len(vid) == 11:
                return vid
        elif parsed.hostname in ['youtu.be', 'www.youtu.be']:
            vid = parsed.path.lstrip('/')
            if len(vid) == 11:
                return vid
    except Exception:
        pass
    
    return None

def to_clean_watch_url(url_or_id: str) -> str:
    """ì§§ì€ ì£¼ì†Œ/íŒŒë¼ë¯¸í„°ë¥¼ í‘œì¤€ watch URLë¡œ ì •ë¦¬."""
    vid = extract_video_id(url_or_id) if "http" in url_or_id else url_or_id
    return f"https://www.youtube.com/watch?v={vid}" if vid else url_or_id

def safe_get_youtube_info(url: str):
    """ì•ˆì „í•œ YouTube ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # pytube ì„¤ì • ê°œì„ 
        yt = YouTube(url, use_oauth=False, allow_oauth_cache=False)
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        _ = yt.title
        return yt
    except Exception as e:
        st.warning(f"YouTube ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        return None

# ---------------------------------
# 1) youtube_transcript_api (ê³µì‹/ìë™ìƒì„±)
# ---------------------------------
def fetch_via_yta(video_id: str, langs: List[str]) -> str:
    """ì—…ë¡œë” ìë§‰ â†’ ìë™ìƒì„± ìë§‰ ìˆœìœ¼ë¡œ ì‹œë„."""
    try:
        tl = YouTubeTranscriptApi.list_transcripts(video_id)
        
        # ì—…ë¡œë” ìë§‰ ë¨¼ì € ì‹œë„
        try:
            tr = tl.find_transcript(langs)
        except Exception:
            # ìë™ìƒì„± ìë§‰ìœ¼ë¡œ í´ë°±
            tr = tl.find_generated_transcript(langs)
        
        entries = tr.fetch()
        st.success(f"ìë§‰ í™•ë³´(yta): lang={tr.language}, auto={tr.is_generated}")
        return "\n".join([f"[{e['start']:.1f}] {e['text']}" for e in entries])
    except (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable):
        # ì›ë³¸ ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        raise TranscriptExtractionError(f"YTA ë°©ì‹ ì‹¤íŒ¨: {str(e)}")

# ---------------------------------
# 2) pytube captions í´ë°± (SRT/XML)
# ---------------------------------
def clean_xml_text(xml_text: str) -> List[tuple]:
    """XMLì—ì„œ (start, text) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    items = []
    xml_text = xml_text.replace("\n", "")
    pattern = r'<text[^>]*start="([\d\.]+)"[^>]*>(.*?)</text>'
    
    for m in re.finditer(pattern, xml_text, re.DOTALL):
        try:
            start = float(m.group(1))
            raw = re.sub(r"<.*?>", " ", m.group(2))
            text = html.unescape(raw)
            text = re.sub(r"\s+", " ", text).strip()
            if text:
                items.append((start, text))
        except ValueError:
            continue
    return items

def fetch_via_pytube(url_or_id: str, langs: List[str]) -> str:
    """pytube ìë§‰ íŠ¸ë™ì—ì„œ ì¶”ì¶œ."""
    url = to_clean_watch_url(url_or_id)
    
    try:
        yt = safe_get_youtube_info(url)
        if not yt:
            raise TranscriptExtractionError("pytube: YouTube ê°ì²´ ìƒì„± ì‹¤íŒ¨")
        
        tracks = yt.captions
        if not tracks:
            raise TranscriptExtractionError("pytube: ìë§‰ íŠ¸ë™ì´ ì—†ìŒ")

        # ì„ í˜¸ ì–¸ì–´ ì½”ë“œ + ìë™ìƒì„± ì½”ë“œ í›„ë³´ êµ¬ì„±
        candidates = []
        for lg in langs:
            candidates.append(lg)
            candidates.append(f"a.{lg}")
        
        # ì˜ì–´ í´ë°±
        if "en" not in [c.replace("a.", "") for c in candidates]:
            candidates.extend(["en", "a.en"])

        available_codes = {c.code: c for c in tracks}

        for code in candidates:
            cap = available_codes.get(code)
            
            # ì§€ì—­ì½”ë“œ ë§¤ì¹­ ì‹œë„ (ì˜ˆ: ko-KR)
            if not cap:
                for k, v in available_codes.items():
                    if k.lower().startswith(code.lower().replace("a.", "")):
                        cap = v
                        break
            
            if not cap:
                continue

            try:
                # SRT í˜•ì‹ìœ¼ë¡œ ì‹œë„
                srt = cap.generate_srt_captions()
                lines = []
                
                for block in srt.strip().split("\n\n"):
                    if not block.strip():
                        continue
                        
                    parts = block.split("\n")
                    if len(parts) >= 3:
                        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
                        ts = parts[1].split("-->")[0].strip()
                        try:
                            h, m, s_ms = ts.split(":")
                            s, ms = s_ms.split(",")
                            start = int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0
                            text = " ".join(parts[2:]).strip()
                            if text:
                                lines.append(f"[{start:.1f}] {text}")
                        except ValueError:
                            continue
                
                if lines:
                    st.success(f"ìë§‰ í™•ë³´(pytube-srt): {code}")
                    return "\n".join(lines)
                    
            except Exception:
                # XML í˜•ì‹ìœ¼ë¡œ í´ë°±
                try:
                    xml = cap.xml_captions
                    items = clean_xml_text(xml)
                    if items:
                        st.success(f"ìë§‰ í™•ë³´(pytube-xml): {code}")
                        return "\n".join([f"[{stt:.1f}] {txt}" for stt, txt in items])
                except Exception:
                    continue

    except Exception as e:
        raise TranscriptExtractionError(f"pytube ë°©ì‹ ì‹¤íŒ¨: {str(e)}")
    
    raise TranscriptExtractionError("pytube: ë§¤ì¹­ë˜ëŠ” ìë§‰ íŠ¸ë™ ì—†ìŒ")

# ---------------------------------
# 3) yt-dlp í´ë°±
# ---------------------------------
def parse_vtt(vtt: str) -> List[str]:
    """WebVTTë¥¼ [start] text í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
    lines = []
    blocks = [b for b in vtt.strip().split("\n\n") if "-->" in b]
    
    for block in blocks:
        rows = block.split("\n")
        if not rows:
            continue
            
        ts = rows[0]
        m = re.match(r"(\d+):(\d+):(\d+(?:\.\d+)?)", ts.replace(",", "."))
        
        start = 0.0
        if m:
            h, m_, s = m.groups()
            start = int(h) * 3600 + int(m_) * 60 + float(s)
        
        text = " ".join(rows[1:]).strip()
        text = re.sub(r"<.*?>", " ", text)
        text = re.sub(r"\s+", " ", text)
        if text:
            lines.append(f"[{start:.1f}] {text}")
    
    return lines

def fetch_via_ytdlp(url_or_id: str, langs: List[str]) -> str:
    """yt-dlpë¡œ ìë§‰ ê°€ì ¸ì˜¤ê¸°."""
    url = to_clean_watch_url(url_or_id)
    
    ydl_opts = {
        "quiet": True,
        "noplaylist": True,
        "writesubtitles": False,
        "writeautomaticsub": False,
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
    except Exception as e:
        raise TranscriptExtractionError(f"yt-dlp ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")

    subs = info.get("subtitles") or {}
    autos = info.get("automatic_captions") or {}

    # í›„ë³´ êµ¬ì„±
    candidates = []
    for lg in langs:
        if lg in subs:
            candidates.append(("subs", lg, subs[lg]))
    for lg in langs:
        if lg in autos:
            candidates.append(("auto", lg, autos[lg]))
    
    # ì˜ì–´ í´ë°±
    if not any(c[1] == "en" for c in candidates):
        if "en" in subs:
            candidates.append(("subs", "en", subs["en"]))
        if "en" in autos:
            candidates.append(("auto", "en", autos["en"]))

    for kind, lg, fmt_list in candidates:
        if not fmt_list:
            continue
            
        # VTT í˜•ì‹ ìš°ì„  ì„ íƒ
        vtt_item = None
        for item in fmt_list:
            if item.get("ext", "").lower() in ("vtt", "webvtt"):
                vtt_item = item
                break
        
        target = vtt_item or fmt_list[0]
        
        try:
            with urlopen(target["url"]) as resp:
                data = resp.read().decode("utf-8", errors="ignore")
            
            if target.get("ext", "").lower() in ("vtt", "webvtt"):
                lines = parse_vtt(data)
                if lines:
                    st.success(f"ìë§‰ í™•ë³´(yt-dlp-{kind}-vtt): {lg}")
                    return "\n".join(lines)
            else:
                # ë‹¤ë¥¸ í˜•ì‹: íƒœê·¸ ì œê±° í›„ í…ìŠ¤íŠ¸ë§Œ
                text = re.sub(r"<.*?>", " ", data)
                text = html.unescape(text)
                text = re.sub(r"\s+", " ", text).strip()
                if text and len(text) > 50:  # ìµœì†Œ ê¸¸ì´ ì²´í¬
                    st.success(f"ìë§‰ í™•ë³´(yt-dlp-{kind}-{target.get('ext','raw')}): {lg}")
                    return text
        except Exception:
            continue

    raise TranscriptExtractionError("yt-dlp: ë§¤ì¹­ë˜ëŠ” ìë§‰ ì†ŒìŠ¤ ì—†ìŒ")

# ---------------------------------
# ìµœì¢… ë˜í¼
# ---------------------------------
def fetch_transcript_resilient(url: str, video_id: str, langs: List[str]) -> str:
    """3ë‹¨ê³„ í´ë°±ìœ¼ë¡œ ìë§‰ ê°€ì ¸ì˜¤ê¸°"""
    errors = []
    
    # 1) youtube_transcript_api
    try:
        return fetch_via_yta(video_id, langs)
    except (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable):
        # ì›ë³¸ ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ ì¬ë°œìƒ (ë§ˆì§€ë§‰ì—)
        errors.append("YTA: ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        time.sleep(0.5)
    except TranscriptExtractionError as e:
        errors.append(f"YTA: {str(e)}")
        time.sleep(0.5)
    except Exception as e:
        errors.append(f"YTA: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {str(e)}")
        time.sleep(0.5)

    # 2) pytube
    try:
        return fetch_via_pytube(url, langs)
    except TranscriptExtractionError as e:
        errors.append(f"pytube: {str(e)}")
        time.sleep(0.5)
    except Exception as e:
        errors.append(f"pytube: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {str(e)}")
        time.sleep(0.5)

    # 3) yt-dlp
    try:
        return fetch_via_ytdlp(url, langs)
    except TranscriptExtractionError as e:
        errors.append(f"yt-dlp: {str(e)}")
    except Exception as e:
        errors.append(f"yt-dlp: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ - {str(e)}")

    # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ìƒì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
    error_msg = " | ".join(errors)
    raise TranscriptExtractionError(f"ëª¨ë“  ë°©ë²• ì‹¤íŒ¨: {error_msg}")

# ---------------------------------
# Streamlit UI
# ---------------------------------
st.set_page_config(page_title="YouTube ìë§‰ ì¶”ì¶œê¸°", layout="wide")
st.title("ğŸ¬ YouTube ìë§‰ ì¶”ì¶œê¸°")
st.caption("YouTube ì˜ìƒì˜ ìë§‰ì„ ì¶”ì¶œí•©ë‹ˆë‹¤. API í‚¤ ë¶ˆí•„ìš”.")

with st.sidebar:
    st.header("ì„¤ì •")
    lang_pref = st.multiselect(
        "ì–¸ì–´ ìš°ì„ ìˆœìœ„ (ìœ„ì—ì„œë¶€í„° ì‹œë„)",
        ["ko", "en", "ja", "zh-Hans", "zh-Hant", "es", "fr", "de"],
        default=["ko", "en"],
        help="ì„ í˜¸í•˜ëŠ” ì–¸ì–´ë¥¼ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì„¸ìš”"
    )
    show_meta = st.toggle("ì˜ìƒ ì œëª©/ê¸¸ì´ í‘œì‹œ", value=True)

url = st.text_input(
    "YouTube ë§í¬", 
    placeholder="https://www.youtube.com/watch?v=... ë˜ëŠ” https://youtu.be/...",
    help="YouTube ì˜ìƒì˜ URLì„ ì…ë ¥í•˜ì„¸ìš”"
)

run = st.button("ìë§‰ ì¶”ì¶œ", type="primary")

if run:
    if not url.strip():
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    # URL ì •ë¦¬ ë° ë¹„ë””ì˜¤ ID ì¶”ì¶œ
    clean_url = to_clean_watch_url(url.strip())
    vid = extract_video_id(clean_url)
    
    if not vid:
        st.error("ìœ íš¨í•œ YouTube ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤. URLì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.info(f"ë¹„ë””ì˜¤ ID: {vid}")

    # ë©”íƒ€ ì •ë³´ í‘œì‹œ
    if show_meta:
        with st.spinner("ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            try:
                yt = safe_get_youtube_info(clean_url)
                if yt:
                    title = yt.title or "ì œëª© í™•ì¸ ë¶ˆê°€"
                    length_min = int((yt.length or 0) / 60)
                    st.info(f"**ì œëª©**: {title}  |  **ê¸¸ì´**: ì•½ {length_min}ë¶„")
                else:
                    st.caption("ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - ìë§‰ ì¶”ì¶œì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            except Exception:
                st.caption("ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - ìë§‰ ì¶”ì¶œì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

    # ìë§‰ ì¶”ì¶œ
    with st.spinner("ìë§‰ ì¶”ì¶œ ì¤‘... (ì—¬ëŸ¬ ë°©ë²•ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤)"):
        try:
            transcript_text = fetch_transcript_resilient(clean_url, vid, lang_pref)
        except (NoTranscriptFound, TranscriptsDisabled) as e:
            st.error(f"ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ì´ ì˜ìƒì€ ìë§‰ì´ ì—†ê±°ë‚˜ ë¹„í™œì„±í™”ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            st.stop()
        except VideoUnavailable:
            st.error("ì˜ìƒì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¹„ê³µê°œ, ì§€ì—­ì œí•œ, ì—°ë ¹ì œí•œ ë“±)")
            st.stop()
        except TranscriptExtractionError as e:
            st.error(f"ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            st.info("ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ë‹¤ë¥¸ ì˜ìƒìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            st.stop()
        except Exception as e:
            st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ë‹¤ë¥¸ ì˜ìƒìœ¼ë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
            st.stop()

    # ê²°ê³¼ ì¶œë ¥
    st.success("ìë§‰ ì¶”ì¶œ ì™„ë£Œ!")
    
    col1, col2 = st.columns([1, 4])
    with col1:
        st.download_button(
            "ğŸ“„ ìë§‰ ë‹¤ìš´ë¡œë“œ (TXT)",
            data=transcript_text.encode("utf-8"),
            file_name=f"transcript_{vid}.txt",
            mime="text/plain",
        )
    
    with col2:
        word_count = len(transcript_text.split())
        st.caption(f"ì´ {word_count:,}ê°œ ë‹¨ì–´")

    st.subheader("ğŸ“„ ì¶”ì¶œëœ ìë§‰")
    st.text_area(
        "", 
        value=transcript_text, 
        height=500,
        help="ìë§‰ ë‚´ìš©ì„ í™•ì¸í•˜ê³  ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.caption(
    "ğŸ’¡ **ì‚¬ìš© íŒ**: ì´ ë„êµ¬ëŠ” ê°œì¸ í•™ìŠµ/ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. "
    "ì¼ë¶€ ì˜ìƒì€ ì €ì‘ê¶Œ, ì—°ë ¹ì œí•œ, ì§€ì—­ì œí•œ ë“±ìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)
