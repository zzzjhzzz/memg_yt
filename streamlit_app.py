import re
import time
import html
from typing import Optional, List
from urllib.parse import urlparse, parse_qs
from urllib.request import urlopen

import streamlit as st
from youtube_transcript_api import (
    YouTubeTranscriptApi,
    NoTranscriptFound,
    TranscriptsDisabled,
    VideoUnavailable,
)
from pytube import YouTube
import yt_dlp


# ---------------------------------
# URL ì •ë¦¬ / ë¹„ë””ì˜¤ID ì¶”ì¶œ
# ---------------------------------
YOUTUBE_URL_RE = re.compile(
    r"(?:youtu\.be/|youtube\.com/(?:watch\?v=|embed/|live/|shorts/))([\w-]{11})"
)

def extract_video_id(url: str) -> Optional[str]:
    if not url:
        return None
    m = YOUTUBE_URL_RE.search(url)
    if m:
        return m.group(1)
    try:
        q = urlparse(url)
        vid = parse_qs(q.query).get("v", [None])[0]
        if vid and len(vid) == 11:
            return vid
    except Exception:
        pass
    return None

def to_clean_watch_url(url_or_id: str) -> str:
    """ì§§ì€ ì£¼ì†Œ/íŒŒë¼ë¯¸í„°ë¥¼ í‘œì¤€ watch URLë¡œ ì •ë¦¬."""
    vid = extract_video_id(url_or_id) if "http" in url_or_id else url_or_id
    return f"https://www.youtube.com/watch?v={vid}" if vid else url_or_id


# ---------------------------------
# ì˜ˆì™¸ ìœ í‹¸: ì¼ê´€ëœ NoTranscriptFound ë°œìƒ
# ---------------------------------
def raise_no_transcript(langs: List[str]) -> None:
    """
    youtube_transcript_api.NoTranscriptFound ëŠ”
    (requested_language_codes, transcript_data) ë‘ ì¸ìë¥¼ ìš”êµ¬í•¨.
    """
    raise NoTranscriptFound(langs, [])


# ---------------------------------
# 1) youtube_transcript_api (ê³µì‹/ìë™ìƒì„±)
# ---------------------------------
def fetch_via_yta(video_id: str, langs: List[str]) -> str:
    """ì—…ë¡œë” ìë§‰ â†’ ìë™ìƒì„± ìë§‰ ìˆœìœ¼ë¡œ ì‹œë„."""
    tl = YouTubeTranscriptApi.list_transcripts(video_id)
    try:
        tr = tl.find_transcript(langs)           # ì—…ë¡œë” ìë§‰
    except Exception:
        tr = tl.find_generated_transcript(langs) # ìë™ìƒì„± ìë§‰
    entries = tr.fetch()
    if not entries:
        raise_no_transcript(langs)
    st.success(f"ìë§‰ í™•ë³´(yta): lang={tr.language}, auto={tr.is_generated}")
    return "\n".join([f"[{e['start']:.1f}] {e['text']}" for e in entries])


# ---------------------------------
# 2) pytube captions í´ë°± (SRT/XML)
# ---------------------------------
def clean_xml_text(xml_text: str) -> List[tuple]:
    """
    <text start="12.34" dur="3.21">ë¬¸ì¥</text> ... í˜•íƒœì˜ XMLì—ì„œ
    (start, text) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    """
    items = []
    xml_text = xml_text.replace("\n", "")
    for m in re.finditer(r'<text[^>]*start="([\d\.]+)"[^>]*>(.*?)</text>', xml_text):
        start = float(m.group(1))
        raw = re.sub(r"<.*?>", " ", m.group(2))
        text = html.unescape(raw)
        text = re.sub(r"\s+", " ", text).strip()
        if text:
            items.append((start, text))
    return items

def fetch_via_pytube(url_or_id: str, langs: List[str]) -> str:
    """pytube ìë§‰ íŠ¸ë™(SRT/XML)ì—ì„œ ì¶”ì¶œ."""
    url = to_clean_watch_url(url_or_id)
    yt = YouTube(url)
    tracks = yt.captions  # CaptionQuery

    # ì„ í˜¸ ì–¸ì–´ ì½”ë“œ + ìë™ìƒì„± ì½”ë“œ(a.xx) í›„ë³´ êµ¬ì„±
    candidates = []
    for lg in langs:
        candidates.append(lg)          # ì—…ë¡œë” ìë§‰
    for lg in langs:
        candidates.append(f"a.{lg}")   # ìë™ìƒì„± ìë§‰
    if "en" not in candidates:
        candidates += ["en", "a.en"]

    available_codes = {c.code: c for c in tracks}

    for code in candidates:
        cap = available_codes.get(code)
        if not cap:
            # ko-KR ê°™ì€ ì§€ì—­ì½”ë“œ ë§¤ì¹­ ë³´ì¡°
            for k, v in available_codes.items():
                if k.lower().startswith(code.lower()):
                    cap = v
                    break
        if not cap:
            continue

        # SRT â†’ íŒŒì‹±, ì‹¤íŒ¨í•˜ë©´ XML íŒŒì‹±
        try:
            try:
                srt = cap.generate_srt_captions()
                lines = []
                for block in srt.strip().split("\n\n"):
                    parts = block.split("\n")
                    if len(parts) >= 3:
                        # "00:00:12,340 --> 00:00:15,120"
                        ts = parts[1].split("-->")[0].strip()
                        h, m, s_ms = ts.split(":")
                        s, ms = s_ms.split(",")
                        start = int(h) * 3600 + int(m) * 60 + int(s) + int(ms) / 1000.0
                        text = " ".join(parts[2:]).strip()
                        if text:
                            lines.append(f"[{start:.1f}] {text}")
                if lines:
                    st.success(f"ìë§‰ í™•ë³´(pytube-srt): {code}")
                    return "\n".join(lines)
            except Exception:
                pass

            xml = cap.xml_captions
            items = clean_xml_text(xml)
            if items:
                st.success(f"ìë§‰ í™•ë³´(pytube-xml): {code}")
                return "\n".join([f"[{stt:.1f}] {txt}" for stt, txt in items])
        except Exception:
            continue

    # ì—¬ê¸°ì— ë„ë‹¬í•˜ë©´ pytubeë¡œëŠ” ì°¾ì§€ ëª»í•¨
    raise_no_transcript(langs)


# ---------------------------------
# 3) yt-dlp í´ë°± (subtitles/automatic_captions)
# ---------------------------------
def parse_vtt(vtt: str) -> List[str]:
    """WebVTTë¥¼ [start] text ì¤„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜."""
    lines = []
    blocks = [b for b in vtt.strip().split("\n\n") if "-->" in b]
    for block in blocks:
        rows = block.split("\n")
        ts = rows[0]  # "00:00:01.000 --> 00:00:03.000"
        # ì‹œì‘ ì‹œê°„ë§Œ ì´ˆë¡œ í™˜ì‚°
        m = re.match(r"(\d+):(\d+):(\d+(?:\.\d+)?)", ts.replace(",", "."))
        start = 0.0
        if m:
            h, m_, s = m.groups()
            start = int(h) * 3600 + int(m_) * 60 + float(s)
        text = " ".join(rows[1:]).strip()
        text = re.sub(r"<.*?>", " ", text)
        text = re.sub(r"\s+", " ", text)
        if text:
            lines.append(f"[{start:.1f}] {text}")
    return lines

def fetch_via_ytdlp(url_or_id: str, langs: List[str]) -> str:
    """yt-dlp ë©”íƒ€ì—ì„œ ìë§‰ íŒŒì¼ URLì„ ì–»ì–´ ì§ì ‘ ë‹¤ìš´ë¡œë“œ/íŒŒì‹±."""
    url = to_clean_watch_url(url_or_id)
    ydl_opts = {"quiet": True, "noplaylist": True}
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info = ydl.extract_info(url, download=False)

    subs = info.get("subtitles") or {}
    autos = info.get("automatic_captions") or {}

    candidates = []
    for lg in langs:
        if lg in subs:
            candidates.append(("subs", lg, subs[lg]))
    for lg in langs:
        if lg in autos:
            candidates.append(("auto", lg, autos[lg]))
    # í´ë°± en
    if not any(c[1] == "en" for c in candidates):
        if "en" in subs:
            candidates.append(("subs", "en", subs["en"]))
        if "en" in autos:
            candidates.append(("auto", "en", autos["en"]))

    # ê° í›„ë³´ëŠ” ì—¬ëŸ¬ í¬ë§·(ì˜ˆ: vtt/ttml/srv3/â€¦) ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§ â†’ vtt ìš°ì„ 
    for kind, lg, lst in candidates:
        vtt_item = None
        first_item = lst[0] if lst else None
        for it in lst:
            ext = it.get("ext", "")
            if ext.lower() in ("vtt", "webvtt"):
                vtt_item = it
                break
        target = vtt_item or first_item
        if not target:
            continue

        try:
            with urlopen(target["url"]) as resp:
                data = resp.read().decode("utf-8", errors="ignore")
            if target.get("ext", "").lower() in ("vtt", "webvtt"):
                lines = parse_vtt(data)
                if lines:
                    st.success(f"ìë§‰ í™•ë³´(yt-dlp-{kind}-vtt): {lg}")
                    return "\n".join(lines)
            else:
                # srv/json/xml ë“±: ìš°ì„  íƒœê·¸ ì œê±°ë¡œ ë¹ ë¥´ê²Œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                text = re.sub(r"<.*?>", " ", data)
                text = html.unescape(text)
                text = re.sub(r"\s+", " ", text).strip()
                if text:
                    st.success(f"ìë§‰ í™•ë³´(yt-dlp-{kind}-{target.get('ext','raw')}): {lg}")
                    return text
        except Exception:
            continue

    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ yt-dlp ê²½ë¡œë¡œë„ ì‹¤íŒ¨
    raise_no_transcript(langs)


# ---------------------------------
# ìµœì¢… ë˜í¼ (YTA â†’ pytube â†’ yt-dlp)
# ---------------------------------
def fetch_transcript_resilient(url: str, video_id: str, langs: List[str]) -> str:
    # 1) youtube_transcript_api
    try:
        return fetch_via_yta(video_id, langs)
    except (NoTranscriptFound, TranscriptsDisabled, VideoUnavailable):
        pass
    except Exception:
        time.sleep(0.5)

    # 2) pytube
    try:
        return fetch_via_pytube(url, langs)
    except NoTranscriptFound:
        pass
    except Exception:
        time.sleep(0.5)

    # 3) yt-dlp
    return fetch_via_ytdlp(url, langs)


# ---------------------------------
# Streamlit UI
# ---------------------------------
st.set_page_config(page_title="YouTube ìë§‰ ì¶”ì¶œê¸° (ë¬´ë£Œ)", layout="wide")
st.title("ğŸ¬ YouTube ìë§‰ ì¶”ì¶œê¸° â€” 0ì› ë²„ì „")
st.caption("ìë§‰ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ASR/ìš”ì•½ ëª¨ë¸ í˜¸ì¶œ ì—†ìŒ â†’ API í‚¤ ë¶ˆí•„ìš”, ì™„ì „ ë¬´ë£Œ.")

with st.sidebar:
    st.header("ì„¤ì •")
    lang_pref = st.multiselect(
        "ì–¸ì–´ ìš°ì„ ìˆœìœ„ (ìœ„ì—ì„œë¶€í„° ì‹œë„)",
        ["ko", "en", "ja", "zh-Hans", "zh-Hant", "es", "fr", "de"],
        default=["ko", "en"],
    )
    show_meta = st.toggle("ì˜ìƒ ì œëª©/ê¸¸ì´ í‘œì‹œ", value=True)

url = st.text_input("YouTube ë§í¬", placeholder="https://www.youtube.com/watch?v=...")
run = st.button("ìë§‰ ì¶”ì¶œ (ë¬´ë£Œ)")

if run:
    if not url:
        st.warning("URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        st.stop()

    clean_url = to_clean_watch_url(url)  # ?t=8s ë“± íŒŒë¼ë¯¸í„° ì •ë¦¬
    vid = extract_video_id(clean_url)
    if not vid:
        st.error("ìœ íš¨í•œ YouTube ë§í¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        st.stop()

    # (ì„ íƒ) ë©”íƒ€ ì •ë³´
    if show_meta:
        try:
            yt = YouTube(clean_url)
            title = yt.title or "ì œëª© í™•ì¸ ë¶ˆê°€"
            length_min = int((yt.length or 0) / 60)
            st.info(f"**ì œëª©**: {title}  |  **ê¸¸ì´**: ì•½ {length_min}ë¶„")
        except Exception:
            st.caption("ì œëª©/ê¸¸ì´ ì¡°íšŒ ì‹¤íŒ¨ â€” ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

    # ìë§‰ ê°€ì ¸ì˜¤ê¸°
    try:
        transcript_text = fetch_transcript_resilient(clean_url, vid, lang_pref)
    except NoTranscriptFound:
        st.error("ì´ ì˜ìƒì€ ìë§‰ì´ ì—†ê±°ë‚˜ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (ë¬´ë£ŒíŒì€ ìë§‰ë§Œ ì²˜ë¦¬ ê°€ëŠ¥)")
        st.stop()
    except TranscriptsDisabled:
        st.error("ì´ ì˜ìƒì€ ìë§‰ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()
    except VideoUnavailable:
        st.error("ì˜ìƒì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¹„ê³µê°œ, ì§€ì—­/ì—°ë ¹ ì œí•œ ë“±)")
        st.stop()
    except Exception as e:
        st.error(f"ìë§‰ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()

    # ì¶œë ¥
    st.subheader("ğŸ“„ Raw ìë§‰")
    st.download_button(
        "ìë§‰ ì €ì¥ (TXT)",
        data=transcript_text.encode("utf-8"),
        file_name="transcript.txt",
        mime="text/plain",
    )
    st.text_area("", value=transcript_text, height=560)

st.markdown("---")
st.caption(
    "ë³¸ ë„êµ¬ëŠ” ê°œì¸ í•™ìŠµ/ì—°êµ¬ ëª©ì ì˜ ìë§‰ ë³´ê¸° ìš©ë„ì…ë‹ˆë‹¤. ì¼ë¶€ ì˜ìƒì€ ë¼ì´ì„ ìŠ¤/ì—°ë ¹/ì§€ì—­ ì œí•œìœ¼ë¡œ ì²˜ë¦¬ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)
